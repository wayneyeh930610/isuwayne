import os
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.vectorstores import FAISS
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings

def create_vector_db_from_pdf(faiss_folder_path="faiss_index"):
    """
    å¾æœ¬åœ°çš„ç¾©å®ˆå¤§å­¸.pdf å»ºç«‹å‘é‡è³‡æ–™åº«ï¼Œä¸¦å„²å­˜è‡³æŒ‡å®šè³‡æ–™å¤¾ã€‚
    """

    # å–å¾— API é‡‘é‘°ï¼ˆå¾ç’°å¢ƒè®Šæ•¸ï¼‰
    openai_api_key = os.getenv("OPENAI_API_KEY")
    if not openai_api_key:
        raise ValueError("âŒ æ‰¾ä¸åˆ°ç’°å¢ƒè®Šæ•¸ OPENAI_API_KEYï¼Œè«‹å…ˆè¨­å®šä½ çš„ OpenAI API é‡‘é‘°ã€‚")

    # 1. ç›´æ¥æŒ‡å®š PDF è·¯å¾‘
    temp_file_path = r"C:\Users\cindy\OneDrive\æ¡Œé¢\ç¾©å®ˆå¤§å­¸.pdf"
    if not os.path.exists(temp_file_path):
        raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ° PDF æª”æ¡ˆï¼š{temp_file_path}")

    # 2. è§£æ PDF
    loader = PyPDFLoader(temp_file_path)
    docs = loader.load()

    # 3. è¨­å®šæ–‡æœ¬åˆ‡åˆ†å™¨
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1500,
        chunk_overlap=200,
        separators=["\n", "ã€‚", "ï¼Ÿ", "!", ":", "ï¼Œ", "ã€", " "]
    )
    texts = text_splitter.split_documents(docs)

    # 4. å»ºç«‹ Embeddings
    embeddings_model = OpenAIEmbeddings(
        model="text-embedding-ada-002",
        openai_api_key=openai_api_key
    )

    # 5. å»ºç«‹å‘é‡è³‡æ–™åº«
    db = FAISS.from_documents(texts, embeddings_model)

    # 6. å„²å­˜å‘é‡è³‡æ–™åº«
    db.save_local(faiss_folder_path)

    print("âœ… æˆåŠŸå»ºç«‹ä¸¦å„²å­˜å‘é‡è³‡æ–™åº«ï¼")
    print("â¡ï¸ ä½ç½®ï¼š", os.path.abspath(faiss_folder_path))
    print(f"ğŸ“„ å‘é‡æ•¸é‡ï¼š{len(texts)}")

    return f"æˆåŠŸå»ºç«‹ä¸¦å„²å­˜ {len(texts)} ç­†å‘é‡è‡³: {faiss_folder_path}"


# âœ… ä¸»ç¨‹å¼åŸ·è¡Œå€
if __name__ == "__main__":
    result = create_vector_db_from_pdf()
    print(result)

# pip install langchain langchain-community faiss-cpu openai pymupdf tiktoken


